\section*{Verwandte Arbeiten}
Bei Information Retrieval handelt es sich um ein Problem aus dem Bereich der Computer Vision, welches bereits seit langem intensiv erforscht wird. In frühen Ansätzen versuchte man vor allem globale Beschreibungen von Bildern zu erstellen, um diese untereinander vergleichen zu können. Diese basierten zum Beispiel auf Farbhistogrammen oder Texturbeschreibungen \cite{early_days}. Allerdings waren diese Ansätze oft sehr anfällig für Unterschiede in Beleuchtung, Skalierung und anderen Transformationen, wie sie bei unterschiedlichen Aufnahmen des selben Motivs auftreten können.
\\
Ein wesentlicher Durchbruch gelang David G. Lowe 2004 mit der Entwicklung des SIFT-Verfahrens (Scale Invariant Feature Transform) \cite{sift}. Hierbei werden mehrere Konzepte vereint um Bildbeschreibungen zu erzeugen, die robuster gegenüber unterschiedlichen Transformationen sind. So arbeitet der SIFT Algorithmus beispielsweise nicht direkt auf den Bildern sondern im sogenannten Scale Space basierend auf unterschiedlich skalierten Versionen des Ursprungsbildes, um Resistenz gegen Skalierung zu schaffen. Das Verfahren nutzt Gauß-Filteroperationen um Merkmale zur Beschreibung hervorzuheben. Im ersten Schritt des Verfahren werden über die Suche nach lokalen Extrema bedeutsame Bildpunkte gewählt, für die anschließend einzelne Deskriptoren gefertigt werden. Das Bild wird also nicht global beschrieben, sondern über viele lokale Deskriptoren dargestellt. Die lokalen Deskriptoren ergeben sich aus Histogrammen der Gradientrichtungen der umliegenden Bildpunkte. Diese werden relativ zu der dominanten Gradientenrichtung in der Umgebung berechnet, was die Deskriptoren invariant gegenüber Rotationen macht. Lowes Entwicklung bildet den Ursprung für viele abgeleitet Verfahren, wie SURF\cite{surf}, PCA-SIFT\cite{pca_sift} und RIFT\cite{rift}. Auch in aktueller Forschung werden noch Image Retrieval Verfahren erforscht, die mit SIFT-Deskriptoren arbeiten \cite{modern_sift_useage}. \\
Da Image Retrieval Systeme meist auf großen Bilddatenbanken eingesetzt werden und somit für eine Suchanfrage viele Vergleiche zwischen Bildern durchgeführt werden müssen ist es sinnvoll Bildrepräsentationen so kompakt wie möglich zu gestalten, um die Laufzeit in Grenzen zu halten. Insbesondere bei Verfahren, die lokale Deskriptoren erstellen und häufig hunderte oder tausende Merkmale pro Bild extrahieren, kann mit einer guten Kodierung viel Rechenzeit gespart werden. Ein beliebter Ansatz zur Erstellung kompakter Darstellungen aus lokalen Deskriptoren ist das BOVW-Modell (Bag-of-Visual-Words) \cite{bow}. Hierbei werden zunächst alle aus einem Datensatz extrahierte Deskriptoren mittels Clusteranalyse (bspw. K-Means-Clustering \cite{k_means}) in Gruppen eingeteilt. Deskriptoren in der gleichen Gruppe werden dabei auf das selbe "visuelle Wort"\ abgebildet. Als Beschreibung des Gesamtbilds dient ein Histogramm über die im Bild enthaltenen visuellen Wörter. Bei diesem Verfahren geht durch den Quantisierungsfehler ein Teil der Information verloren. Das ebenfalls auf Clustering basierte VLAD-Verfahren \cite{vlad} versucht diese Information nutzbar zu machen, indem es statt der Vorkommen die Quantisierungsfehler akkumuliert, die beim abbilden auf die nächsten visuellen Worte entstehen. \\
Der finale Teil einer Image Retrieval Pipeline ist das Vergleichen des Anfragebildes mit den Bildern in der Suchdatenbank auf Basis der erzeugten Deskriptoren, mittels einer geeigneten Distanzmetrik (z.B. euklidische Distanz). Dabei ist ein erschöpfender Suchansatz auf Grund der Menge an Daten oft nicht sinnvoll. Stattdessen 
ANN kd trees pq local sensitive hashing
